# ============================================
# ANALYTICAL TEAM CONFIGURATION
# ============================================

# LLM Mode: LOCAL, CLOUD, or HYBRID
# - LOCAL: All processing on your machine (LM Studio) - MAXIMUM PRIVACY
# - CLOUD: Use cloud APIs (OpenAI, Anthropic) - requires API keys
# - HYBRID: Route based on data sensitivity
ANALYTICAL_LLM_MODE=LOCAL

# LM Studio Server Configuration
LM_STUDIO_URL=http://localhost:1234/v1
LM_STUDIO_TIMEOUT=120

# Model name for analytical team
# Your model: gpt-oss-20b (20 billion parameters - excellent for analytical work!)
LM_STUDIO_MODEL=gpt-oss-20b

# Embedding model for semantic search
# Jina Embeddings v4 - OPTIMAL for analytical documents!
# - Handles tables, structured data, long documents (8192 tokens)
# - Better for: market reports, financial statements, legal docs
# - Load in LM Studio: jinaai/jina-embeddings-v4-text-retrieval
EMBEDDING_MODEL=jinaai/jina-embeddings-v4-text-retrieval

# ============================================
# PRIVACY SETTINGS
# ============================================

# Treat all data as sensitive by default
# (routes to local LLM in HYBRID mode)
DATA_SENSITIVE_BY_DEFAULT=true

# ============================================
# SEARCH INFRASTRUCTURE
# ============================================

# Elasticsearch Configuration
ELASTICSEARCH_URL=http://localhost:9200
ELASTICSEARCH_USER=elastic
ELASTICSEARCH_PASSWORD=changeme123
ELASTICSEARCH_INDEX=analytical-documents

# Qdrant Configuration
QDRANT_URL=http://localhost:6333
QDRANT_COLLECTION=analytical-team

# ============================================
# PROJECT SETTINGS
# ============================================

# Project ID for database separation
ANALYTICAL_PROJECT_ID=destiny-analytical-team

# ============================================
# CLOUD LLM (Optional - only if using CLOUD or HYBRID mode)
# ============================================

# OpenAI API Key (leave empty if using LOCAL mode)
# OPENAI_API_KEY=sk-...

# Anthropic API Key (leave empty if using LOCAL mode)
# ANTHROPIC_API_KEY=sk-ant-...

# ============================================
# PRIVACY GUARANTEE
# ============================================
# 
# When ANALYTICAL_LLM_MODE=LOCAL:
# ✅ All AI processing happens on your machine
# ✅ Sensitive data NEVER leaves your infrastructure
# ✅ No external API calls
# ✅ No usage tracking
# ✅ No rate limits
# ✅ No API costs
# ✅ Complete control over your data
#
# Agents that ALWAYS use local LLM (even in HYBRID mode):
# - Elena Volkov (OSINT - sensitive investigations)
# - Marcus Chen (Financial - confidential data)
# - Adrian Kowalski (Legal - attorney-client privilege)
# - Viktor Kovalenko (Orchestrator - sees all data)
# - Damian Rousseau (Devil's Advocate - full context)
# - Alex Morgan (Technical Liaison - handles sensitive docs)
#
# ============================================
