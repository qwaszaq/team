{
  "file_path": "docs/guides/HYBRID_SYSTEM_QUICK_START.md",
  "title": "\ud83d\ude80 HYBRID ON-PREM SYSTEM - Quick Start Guide",
  "document_type": "architecture",
  "content": "# \ud83d\ude80 HYBRID ON-PREM SYSTEM - Quick Start Guide\n\n**Local LLM Worker + Cloud Supervisor = Professional Intelligence**\n\n---\n\n## \ud83c\udfaf What This System Does\n\n**Problem:** Cloud LLMs are expensive, raise privacy concerns, create dependencies\n\n**Solution:** Hybrid architecture\n- **Local LLM (LMStudio):** Executes investigations using on-prem tools (90% cost savings!)\n- **Aleksander (Claude):** Supervises quality, reviews output, ensures professional standards\n- **Local Tools:** Scraping, statistics, databases - all running locally\n- **Result:** Privacy + Cost Savings + Professional Quality\n\n---\n\n## \ud83d\udccb Prerequisites\n\n### **1. LMStudio Installed**\n\nDownload from: https://lmstudio.ai/\n\n**Recommended Models (choose one):**\n- **Mixtral 8x7B Instruct** (Q4 or Q5) - Best balance\n- **Llama 3 70B Instruct** (Q4) - High quality, needs more RAM\n- **Qwen 2.5 32B Instruct** (Q5) - Good Polish language support\n- **DeepSeek Coder 33B** (Q5) - If focus on code/technical\n\n**Model Requirements:**\n- Function calling support (OpenAI-compatible)\n- Context window: 32k+ tokens\n- RAM: 16GB minimum (32GB+ recommended for 70B models)\n\n### **2. Python Environment**\n\n```bash\n# Python 3.9+\npython --version\n\n# Install dependencies\npip install -r requirements.txt\n```\n\n### **3. Local Toolkits**\n\nAlready implemented:\n- \u2705 ScrapingToolkit (`agents/analytical/tools/scraping_toolkit.py`)\n- \u2705 MathematicalToolkit (`agents/analytical/tools/mathematical_toolkit.py`)\n\nOptional dependencies:\n```bash\n# For dynamic web scraping\npip install playwright\nplaywright install chromium\n\n# For better user agents\npip install fake-useragent\n```\n\n---\n\n## \ud83c\udfc1 Quick Start (5 minutes)\n\n### **Step 1: Start LMStudio**\n\n1. Open LMStudio\n2. Load a model (e.g., Mixtral 8x7B Instruct)\n3. Go to \"Local Server\" tab\n4. Click \"Start Server\"\n5. Verify server running at `http://localhost:1234`\n\n### **Step 2: Test Local LLM**\n\n```bash\ncd /Users/artur/coursor-agents-destiny-folder\n\n# Run basic test\npython local_orchestrator.py\n```\n\n**What Happens:**\n- Local LLM receives investigation task\n- Uses tools (scrape_webpage, archive_source, calculate_statistics)\n- Logs all actions to `./logs/local_llm/`\n- Saves results to `./shared_workspace/results/`\n\n**Expected Output:**\n```\n\ud83d\ude80 LOCAL LLM ORCHESTRATOR - Proof of Concept\n============================================================\n\u2705 LocalLLMOrchestrator initialized\n   LMStudio: http://localhost:1234/v1\n   Model: local-model\n   Tools: 3 available\n\n============================================================\n\ud83d\udd0d INVESTIGATION: test_cpk_research\n============================================================\nTask: Research the concept of \"Central Transportation Hub\" (CPK) in Poland...\n\n--- Iteration 1/5 ---\n\ud83e\udd16 LLM Call: 2 messages\n\ud83d\udcac LLM Response: 245 tokens\n\ud83d\udd27 Executing 2 tool(s)...\n\ud83d\udd27 Tool: scrape_webpage\n\ud83d\udd27 Tool: archive_source\n\n--- Iteration 2/5 ---\n...\n\n\u2705 INVESTIGATION COMPLETE\n============================================================\nStatus: complete\nIterations: 3\nActions logged: 12\nResult file: ./shared_workspace/results/result_test_cpk_research.json\n```\n\n### **Step 3: Supervisor Review**\n\n```bash\n# Aleksander (Claude via Cursor) reviews the work\npython supervisor_interface.py\n```\n\n**What Happens:**\n- Aleksander reads investigation logs\n- Analyzes tool usage quality\n- Checks source attribution compliance\n- Evaluates analytical rigor\n- Generates quality report\n\n**Expected Output:**\n```\n\ud83c\udfaf SUPERVISOR INTERFACE - Quality Assurance\n======================================================================\n\n\ud83d\udccb Pending Investigations: 1\n\n======================================================================\n\ud83d\udd0d Reviewing: test_cpk_research\n======================================================================\n\n\ud83d\udcca SUPERVISOR QUALITY REPORT\n======================================================================\nInvestigation ID: test_cpk_research\nSupervisor: Aleksander (Claude Sonnet 4.5)\n\n======================================================================\nOVERALL GRADE: A\nReady for Publication: \u2705 YES\n======================================================================\n\n\ud83d\udcc8 Execution Metrics:\n   Status: complete\n   Iterations: 3\n   LLM Calls: 3\n   Total Tokens: 1,247\n   Efficiency: HIGH\n\n\ud83d\udd27 Tool Usage:\n   Total Calls: 8\n   Tools: {'scrape_webpage': 4, 'archive_source': 4}\n   Errors: 0\n   Assessment: EXCELLENT\n\n\ud83d\udcda Source Quality:\n   Scraped: 4\n   Archived: 4\n   Archive Ratio: 100.0%\n   Compliance: EXCELLENT\n   Grade: A+\n   Protocol Compliant: \u2705\n\n\u2705 Strengths:\n   \u2022 Appropriate tool usage\n   \u2022 Full SOURCE ATTRIBUTION PROTOCOL compliance\n   \u2022 Efficient investigation (few iterations)\n```\n\n---\n\n## \ud83c\udfaf Production Workflow\n\n### **Investigation Cycle:**\n\n```\n1. USER REQUEST (Artur)\n   \u2193\n   \"Zbadaj temat X u\u017cywaj\u0105c lokalnego systemu\"\n\n2. ALEKSANDER (Supervisor) - Strategic Planning\n   \u2193\n   Creates task definition:\n   {\n     \"task\": \"Investigate X\",\n     \"tools_required\": [\"scrape_webpage\", \"archive_source\"],\n     \"quality_requirements\": {...}\n   }\n   \u2192 Saves: shared_workspace/tasks/task_001.json\n\n3. LOCAL LLM (Worker) - Tactical Execution\n   \u2193\n   python local_orchestrator.py --task-file task_001.json\n   \n   - Reads task\n   - Executes using tools\n   - Logs everything\n   - Saves result\n   \n   \u2192 Logs: logs/local_llm/investigation_001.jsonl\n   \u2192 Result: shared_workspace/results/result_001.json\n\n4. ALEKSANDER (Supervisor) - Quality Review\n   \u2193\n   python supervisor_interface.py --review investigation_001\n   \n   - Analyzes logs\n   - Checks quality\n   - Generates report\n   \n   \u2192 Report: shared_workspace/reports/quality_report_001.json\n\n5. DECISION:\n   \n   IF quality >= A:\n      Aleksander synthesizes final professional report\n      \u2192 DONE \u2705\n   \n   ELSE:\n      Aleksander creates guidance\n      \u2192 shared_workspace/guidance/guidance_001.json\n      \u2192 Local LLM iterates (back to step 3)\n```\n\n---\n\n## \ud83d\udcdd Example: Custom Investigation\n\n### **Scenario: Research Robert Telus CPK Transaction**\n\n**Step 1: Create Task (Aleksander)**\n\n```python\n# In Cursor, Aleksander creates:\ntask = {\n    \"task_id\": \"telus_investigation\",\n    \"objective\": \"Research Robert Telus CPK land transaction\",\n    \"subtasks\": [\n        {\n            \"description\": \"Collect news articles about Telus and CPK\",\n            \"tools\": [\"scrape_webpage\", \"archive_source\"],\n            \"min_sources\": 10\n        },\n        {\n            \"description\": \"Analyze land price data if available\",\n            \"tools\": [\"calculate_statistics\"],\n            \"analysis_required\": \"market comparison\"\n        }\n    ],\n    \"quality_requirements\": {\n        \"source_attribution\": \"mandatory\",\n        \"archiving\": \"all_sources\",\n        \"minimum_sources\": 10\n    }\n}\n\n# Save to shared_workspace/tasks/task_telus_investigation.json\n```\n\n**Step 2: Execute (Local LLM)**\n\n```python\nfrom local_orchestrator import LocalLLMOrchestrator\n\norchestrator = LocalLLMOrchestrator()\n\n# Load task\nwith open(\"shared_workspace/tasks/task_telus_investigation.json\") as f:\n    task = json.load(f)\n\n# Execute\nresult = orchestrator.run_investigation(\n    task=task[\"objective\"],\n    context={\"subtasks\": task[\"subtasks\"]},\n    investigation_id=\"telus_investigation\",\n    max_iterations=20\n)\n\n# Result saved automatically to shared_workspace/results/\n```\n\n**Step 3: Review (Aleksander)**\n\n```python\nfrom supervisor_interface import SupervisorInterface\n\nsupervisor = SupervisorInterface()\n\n# Generate quality report\nreport = supervisor.generate_quality_report(\"telus_investigation\")\n\n# Print report\nsupervisor.print_quality_report(report)\n\n# If needs improvement, provide guidance\nif not report['overall_assessment']['ready_for_publication']:\n    guidance = supervisor.create_guidance(\n        investigation_id=\"telus_investigation\",\n        guidance_text=\"\"\"\n        Investigation quality: B\n        \n        Issues:\n        - Only 7 sources archived (required: 10)\n        - Missing statistical analysis of land prices\n        \n        Next steps:\n        1. Find 3 more credible sources about CPK land transactions\n        2. Use calculate_statistics on any price data found\n        3. Ensure all sources archived\n        \"\"\",\n        priority=\"high\",\n        specific_actions=[\n            \"Scrape 3 more news sources\",\n            \"Archive all new sources\",\n            \"Perform statistical analysis if data available\"\n        ]\n    )\n```\n\n**Step 4: Iterate if Needed**\n\n```python\n# Local LLM reads guidance and continues\nguidance_file = \"shared_workspace/guidance/guidance_telus_investigation_20251104_160000.json\"\n\nwith open(guidance_file) as f:\n    guidance = json.load(f)\n\n# Continue investigation with guidance\nresult = orchestrator.run_investigation(\n    task=f\"Continue previous investigation. Guidance: {guidance['guidance']}\",\n    investigation_id=\"telus_investigation_v2\",\n    max_iterations=10\n)\n```\n\n**Step 5: Final Report (Aleksander)**\n\nOnce quality is A/A+, Aleksander synthesizes final professional report using all findings.\n\n---\n\n## \ud83d\udd27 Configuration\n\n### **LMStudio Settings**\n\nRecommended settings for function calling:\n\n```json\n{\n  \"temperature\": 0.7,\n  \"top_p\": 0.9,\n  \"top_k\": 40,\n  \"max_tokens\": 2048,\n  \"repeat_penalty\": 1.1,\n  \"context_length\": 32768,\n  \"gpu_layers\": -1\n}\n```\n\n### **Orchestrator Configuration**\n\nEdit `local_orchestrator.py`:\n\n```python\norchestrator = LocalLLMOrchestrator(\n    lmstudio_url=\"http://localhost:1234/v1\",  # LMStudio endpoint\n    model_name=\"mixtral-8x7b-instruct\",       # Model identifier\n    log_dir=\"./logs/local_llm\",               # Where to store logs\n    workspace_dir=\"./shared_workspace\"        # Communication directory\n)\n```\n\n### **Supervisor Configuration**\n\nEdit `supervisor_interface.py`:\n\n```python\nsupervisor = SupervisorInterface(\n    workspace_dir=\"./shared_workspace\"  # Must match orchestrator\n)\n```\n\n---\n\n## \ud83d\udcca Monitoring & Debugging\n\n### **Check Investigation Logs**\n\n```bash\n# View latest investigation log\ntail -f logs/local_llm/investigation_*.jsonl\n\n# Pretty print\ncat logs/local_llm/investigation_20251104_153000.jsonl | jq .\n```\n\n### **Check Results**\n\n```bash\n# View investigation result\ncat shared_workspace/results/result_inv_20251104_153000.json | jq .\n```\n\n### **Check Quality Reports**\n\n```bash\n# View supervisor assessment\ncat shared_workspace/reports/quality_report_inv_20251104_153000.json | jq .\n```\n\n### **Common Issues**\n\n**Issue 1: LMStudio Connection Failed**\n```\nError: LMStudio API call failed: Connection refused\n\nSolution:\n1. Check LMStudio is running\n2. Verify server started (green indicator)\n3. Check URL: http://localhost:1234\n4. Try curl http://localhost:1234/v1/models\n```\n\n**Issue 2: Tool Errors**\n```\nError: ScrapingToolkit not available\n\nSolution:\n1. Check imports: from agents.analytical.tools.scraping_toolkit import ScrapingToolkit\n2. Verify file exists: agents/analytical/tools/scraping_toolkit.py\n3. Install dependencies: pip install beautifulsoup4 requests\n```\n\n**Issue 3: Model Not Responding**\n```\nError: Timeout after 180 seconds\n\nSolution:\n1. Check model loaded in LMStudio\n2. Increase timeout in call_llm() method\n3. Try smaller model (less RAM required)\n4. Check GPU layers setting (reduce if needed)\n```\n\n---\n\n## \ud83c\udf93 Best Practices\n\n### **For Local LLM (Worker):**\n\n1. **Always archive sources** - Use `archive_source` for every `scrape_webpage`\n2. **Use appropriate tools** - Statistical data? Use `calculate_statistics`\n3. **Log everything** - Structured logging helps supervisor review\n4. **Be honest** - Report what you found vs. what you couldn't find\n5. **Cite sources** - Include URLs, dates, credibility in all findings\n\n### **For Aleksander (Supervisor):**\n\n1. **Review thoroughly** - Check tool usage, source quality, analytical rigor\n2. **Be specific in guidance** - \"Find 3 more sources\" not \"do better\"\n3. **Praise good work** - Acknowledge when local LLM does well\n4. **Set clear standards** - Define what \"A\" grade looks like\n5. **Final synthesis** - Add professional polish to final reports\n\n---\n\n## \ud83d\udcb0 Cost Comparison\n\n### **Traditional Cloud-Only:**\n\n**Example:** 100 investigations/month\n\n```\nInvestigation: 500k tokens average\nCost: $15/million tokens (Claude)\n\nTotal: 100 \u00d7 500k \u00d7 $15/1M = $750/month\nAnnual: $9,000\n```\n\n### **Hybrid On-Prem:**\n\n```\nLocal LLM (execution): $0 (one-time hardware investment)\nAleksander (supervision): ~50k tokens/investigation\nCost: 100 \u00d7 50k \u00d7 $15/1M = $75/month\nAnnual: $900\n\nSavings: $8,100/year (90% reduction!) \ud83d\udcb0\n```\n\n**Plus:**\n- \u2705 Privacy (data stays local)\n- \u2705 No rate limits\n- \u2705 Full control\n- \u2705 Professional quality maintained\n\n---\n\n## \ud83d\ude80 Next Steps\n\n### **Phase 1: Test Basic System (Today)**\n\n1. \u2705 Install LMStudio\n2. \u2705 Load model (Mixtral 8x7B recommended)\n3. \u2705 Run `local_orchestrator.py` test\n4. \u2705 Run `supervisor_interface.py` review\n5. \u2705 Verify full workflow works\n\n### **Phase 2: Real Investigation (This Week)**\n\n1. \ud83c\udfaf Choose real investigation topic\n2. \ud83c\udfaf Aleksander creates detailed task\n3. \ud83c\udfaf Local LLM executes\n4. \ud83c\udfaf Aleksander reviews and iterates\n5. \ud83c\udfaf Synthesize professional final report\n\n**Suggested First Investigation:**\n- Analyze CPK public data (less sensitive than Telus initially)\n- Scrape CPK official website\n- Collect 10+ sources\n- Statistical analysis of published data\n- Full source attribution\n- **Prove system works end-to-end**\n\n### **Phase 3: Advanced Features (Next 2 Weeks)**\n\n1. \ud83d\udd28 Add Image Intelligence Toolkit\n2. \ud83d\udd28 Add Geolocation Toolkit\n3. \ud83d\udd28 Integrate with local databases (PostgreSQL, Qdrant)\n4. \ud83d\udd28 Automated guidance implementation\n5. \ud83d\udd28 Multi-investigation orchestration\n\n---\n\n## \ud83d\udcda Additional Resources\n\n**Documentation:**\n- Full Architecture: `docs/architecture/HYBRID_ONPREM_INTELLIGENCE_SYSTEM.md`\n- Source Attribution Protocol: `docs/protocols/SOURCE_ATTRIBUTION_PROTOCOL.md`\n- Toolkits Documentation: `agents/analytical/tools/README.md`\n\n**Code:**\n- Local Orchestrator: `local_orchestrator.py`\n- Supervisor Interface: `supervisor_interface.py`\n- Scraping Toolkit: `agents/analytical/tools/scraping_toolkit.py`\n- Mathematical Toolkit: `agents/analytical/tools/mathematical_toolkit.py`\n\n**Logs & Results:**\n- Investigation Logs: `./logs/local_llm/`\n- Results: `./shared_workspace/results/`\n- Quality Reports: `./shared_workspace/reports/`\n- Guidance: `./shared_workspace/guidance/`\n\n---\n\n## \ud83c\udfaf Success Criteria\n\n**System is successful when:**\n\n1. \u2705 Local LLM executes investigations autonomously\n2. \u2705 All sources properly attributed and archived\n3. \u2705 Aleksander can effectively review and guide\n4. \u2705 Quality maintained at Bellingcat standards\n5. \u2705 Cost reduced by 80-90%\n6. \u2705 Privacy preserved (sensitive data stays local)\n7. \u2705 Faster than cloud-only (no rate limits)\n\n**Ready to start? Run `python local_orchestrator.py`!** \ud83d\ude80\n\n---\n\n**Questions? Issues? Artur - just ask Aleksander in Cursor!** \ud83c\udfaf\n",
  "indexed_at": "2025-11-04T19:35:55.935909",
  "source": "realtime_watcher"
}