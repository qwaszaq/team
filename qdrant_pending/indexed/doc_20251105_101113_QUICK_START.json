{
  "file_path": "QUICK_START.md",
  "title": "\ud83d\ude80 QUICK START - Destiny Analytical System",
  "document_type": "architecture",
  "content": "# \ud83d\ude80 QUICK START - Destiny Analytical System\n\nGet up and running in 5 minutes!\n\n---\n\n## \u2705 Prerequisites\n\n```bash\n# 1. LMStudio running on 192.168.200.226:1234\n#    - Model: openai/gpt-oss-20b OR gemma-3-12b-it\n#    - Embeddings: e5-large AND jina\n\n# 2. Python 3.10+\npython3 --version\n\n# 3. (Optional) PostgreSQL for persistence\n```\n\n---\n\n## \ud83c\udfaf Run Your First Analysis\n\n### Option 1: Quick Test (No Installation)\n\n```bash\ncd /Users/artur/coursor-agents-destiny-folder\n\n# Test LLM\npython3 src/llm/lmstudio_client.py\n\n# Test embeddings\npython3 src/data/embedding_pipeline.py\n\n# Test agents\npython3 src/agents/base_agent.py\n```\n\n### Option 2: Full Integration Test\n\n```bash\n# Run complete integration test suite\npython3 tests/integration/test_end_to_end.py\n```\n\n**Expected Result:**\n```\n\ud83c\udf89 ALL TESTS PASSED! SYSTEM IS OPERATIONAL! \ud83c\udf89\n```\n\n---\n\n## \ud83d\udcdd Your First Analysis Script\n\nCreate `my_analysis.py`:\n\n```python\nfrom src.agents.orchestrator import MultiAgentOrchestrator\n\n# Initialize orchestrator\norchestrator = MultiAgentOrchestrator()\n\n# Your documents\ndocuments = [\n    {\n        \"id\": \"doc_001\",\n        \"content\": \"\"\"\n        Q4 2024 Financial Report:\n        Revenue: $5M (up 25% YoY)\n        Profit margin: 32%\n        Cash position: $10M\n        \"\"\",\n        \"type\": \"financial\"\n    }\n]\n\n# Run analysis\nanalysis = orchestrator.process_case(\n    case_id=\"my_first_case\",\n    title=\"My First Analysis\",\n    documents=documents,\n    analysis_types=[\"financial\", \"risk\"]\n)\n\n# View results\nprint(f\"Analysis complete in {analysis.total_time:.2f}s\")\nprint(f\"Confidence: {analysis.average_confidence:.2f}\")\nprint(f\"\\n{analysis.synthesis}\")\n```\n\nRun it:\n```bash\npython3 my_analysis.py\n```\n\n---\n\n## \ud83d\udd27 What Each Component Does\n\n### LLM Client (`src/llm/lmstudio_client.py`)\n- Connects to your local LLM\n- Handles chat completions\n- Tracks tokens & performance\n\n### Embedding Pipeline (`src/data/embedding_pipeline.py`)\n- Generates embeddings\n- Auto-routes to best model\n- Chunks documents smartly\n\n### Agents (`src/agents/base_agent.py`)\n- Financial analysis\n- Legal analysis\n- Risk analysis\n- Context-aware processing\n\n### Orchestrator (`src/agents/orchestrator.py`)\n- Coordinates all agents\n- Manages workflow\n- Synthesizes results\n\n---\n\n## \ud83d\udcca Check System Health\n\n```python\nfrom src.llm.lmstudio_client import LMStudioLLMClient\n\nclient = LMStudioLLMClient()\nhealthy = client.health_check()\nprint(f\"System: {'\u2705 Healthy' if healthy else '\u274c Down'}\")\n```\n\n---\n\n## \ud83c\udfaf Common Use Cases\n\n### 1. Single Document Analysis\n```python\norchestrator.process_case(\n    case_id=\"single_doc\",\n    title=\"Quick Analysis\",\n    documents=[{\"id\": \"doc1\", \"content\": \"...\"}],\n    analysis_types=[\"financial\"]\n)\n```\n\n### 2. Multi-Document Deep Dive\n```python\norchestrator.process_case(\n    case_id=\"deep_dive\",\n    title=\"Comprehensive Analysis\",\n    documents=[doc1, doc2, doc3],\n    analysis_types=[\"financial\", \"legal\", \"risk\"]\n)\n```\n\n### 3. Semantic Search (when DB is set up)\n```python\nresults = orchestrator.semantic_search(\n    query=\"What were the revenue trends?\",\n    case_id=\"my_case\",\n    limit=5\n)\n```\n\n---\n\n## \u2699\ufe0f Configuration\n\n### Change LLM Model\n```python\nfrom src.llm.lmstudio_client import LMStudioLLMClient\n\n# Use fast model\nclient = LMStudioLLMClient(model=\"gemma-3-12b-it\")\n\n# Use quality model\nclient = LMStudioLLMClient(model=\"openai/gpt-oss-20b\")\n```\n\n### Change Embedding Model\n```python\nfrom src.data.embedding_pipeline import DualEmbeddingSystem\n\nembedder = DualEmbeddingSystem()\n\n# Force specific model\nresult = embedder.embed(\"text\", force_model=\"jina\")\n```\n\n---\n\n## \ud83d\udcc8 Performance Expectations\n\n```\nSingle Agent:     3-10 seconds\nMulti-Agent (3):  15-25 seconds\nEmbeddings:       20-40ms each\nThroughput:       40-50 embeddings/sec\n```\n\n---\n\n## \ud83d\udc1b Troubleshooting\n\n### LLM Not Responding\n```bash\n# Check LMStudio is running\ncurl http://192.168.200.226:1234/v1/models\n\n# Should return list of models\n```\n\n### \"No module named 'psycopg2'\"\n```bash\n# PostgreSQL client (optional, for persistence)\npip3 install psycopg2-binary --break-system-packages\n```\n\n### Slow Performance\n```python\n# Use fast model\nclient = LMStudioLLMClient(model=\"gemma-3-12b-it\")\n\n# Reduce max_tokens\nclient = LMStudioLLMClient(max_tokens=1000)\n```\n\n---\n\n## \ud83c\udf93 Next Steps\n\n1. \u2705 Run integration tests\n2. \u2705 Try example analysis\n3. \ud83d\udcca Set up PostgreSQL (optional)\n4. \ud83d\udcda Read full documentation\n5. \ud83d\ude80 Build your own agents\n\n---\n\n## \ud83d\udcda More Resources\n\n- **Full README:** `README.md`\n- **Architecture:** `docs/architecture/`\n- **API Docs:** `docs/api/`\n- **Test Suite:** `tests/integration/`\n\n---\n\n## \ud83d\udcac Quick Commands\n\n```bash\n# Test everything\npython3 tests/integration/test_end_to_end.py\n\n# Test LLM only\npython3 src/llm/lmstudio_client.py\n\n# Test embeddings only\npython3 src/data/embedding_pipeline.py\n\n# Test agents only\npython3 src/agents/base_agent.py\n\n# Full orchestration test\npython3 src/agents/orchestrator.py\n\n# Count lines of code\nfind src -name \"*.py\" -exec wc -l {} + | tail -1\n```\n\n---\n\n## \u2705 System Status\n\n```\n\u2705 LLM Client: WORKING\n\u2705 Embeddings: WORKING\n\u2705 Agents: WORKING\n\u2705 Orchestrator: WORKING\n\u2705 Tests: 5/5 PASSING\n\u26a0\ufe0f Database: OPTIONAL (ready when needed)\n\nStatus: FULLY OPERATIONAL \ud83d\ude80\n```\n\n---\n\n*\"From zero to analysis in 5 minutes!\"*\n\n**Happy analyzing!** \ud83c\udf89\n",
  "indexed_at": "2025-11-05T10:11:13.704847",
  "source": "realtime_watcher"
}