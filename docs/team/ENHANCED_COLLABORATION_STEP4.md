# Enhanced Collaboration System - Step 4: Consensus Builder

**Date:** 2025-11-04  
**Component:** ConsensusBuilder  
**Status:** âœ… Implemented  
**Branch:** feature/enhanced-cross-team-collaboration

---

## ğŸ¯ Purpose

Build consensus between teams through structured position tracking, common ground detection, and compromise proposals.

---

## ğŸ”§ Component: ConsensusBuilder

### Features

**1. Position Registration**
- Team position tracking
- Key points identification
- Non-negotiable requirements
- Timestamp tracking

**2. Common Ground Detection**
- Keyword-based similarity
- Agreement strength calculation
- Unique position identification
- Conflict detection

**3. Compromise Proposals**
- Automatic compromise generation
- Optional feature suggestions
- Discussion area identification

**4. Consensus Measurement**
- Consensus score (0-1)
- Team alignment tracking
- Agreement/disagreement ratio
- Progress monitoring

---

## ğŸ“‹ API Reference

### Initialization

```python
from agents.enhanced_collaboration import ConsensusBuilder

builder = ConsensusBuilder(
    topic="Skills Routing Implementation",
    teams=["analytical", "technical"]
)
```

### Register Position

```python
builder.register_position(
    team="analytical",
    position="Need accurate intent detection",
    key_points=[
        "User-friendly natural language",
        "High accuracy (>80%)",
        "Fast response (<200ms)"
    ],
    non_negotiables=["High accuracy"]
)
```

### Find Common Ground

```python
common = builder.find_common_ground()

# Returns:
{
    "common_ground": [
        {
            "point": str,
            "teams_agreeing": List[str],
            "agreement_strength": float  # 0.0 - 1.0
        }
    ],
    "unique_positions": {
        "team_name": List[str]  # Unique points per team
    },
    "conflicts": [
        {
            "team1": str,
            "position1": str,
            "team2": str,
            "position2": str,
            "conflict_type": str
        }
    ],
    "agreement_areas": int,
    "conflict_areas": int
}
```

### Track Agreement

```python
builder.track_agreement(
    teams_agreeing=["analytical", "technical"],
    agreed_point="Use keyword matching with <10ms target",
    rationale="Meets both speed and simplicity requirements"
)
```

### Get Consensus Score

```python
score = builder.get_consensus_score()
# Returns: float (0.0 - 1.0)

# 0.0 - 0.3: Low consensus
# 0.3 - 0.7: Moderate consensus
# 0.7 - 1.0: High consensus
```

### Propose Compromise

```python
compromise = builder.propose_compromise()

# Returns:
{
    "agreed_points": List[Dict],  # Already agreed items
    "compromise_proposals": List[Dict],  # Compromise suggestions
    "areas_for_discussion": List[Dict],  # Conflicts needing discussion
    "optional_features": {  # Team-specific features
        "description": str,
        "suggestions": List[Dict]
    }
}
```

### Get Team Alignment

```python
alignment = builder.get_team_alignment()

# Returns: Dict[str, float]
{
    "analytical": 0.85,  # 85% aligned with consensus
    "technical": 0.90    # 90% aligned with consensus
}
```

---

## ğŸ’¡ Usage Example

```python
from agents.enhanced_collaboration import ConsensusBuilder

# Create builder
builder = ConsensusBuilder(
    topic="Skills Routing Implementation",
    teams=["analytical", "technical"]
)

# TURN 1: Analytical team position
builder.register_position(
    team="analytical",
    position="Need accurate and user-friendly routing",
    key_points=[
        "Natural language understanding",
        "High accuracy (>80%)",
        "Fast response",
        "Easy for users"
    ],
    non_negotiables=["High accuracy"]
)

# TURN 2: Technical team position
builder.register_position(
    team="technical",
    position="Need simple and maintainable solution",
    key_points=[
        "No complex dependencies",
        "Very fast (<10ms)",
        "Easy to debug",
        "Simple implementation"
    ],
    non_negotiables=["Simple implementation"]
)

# Find common ground
common = builder.find_common_ground()
print(f"Common ground: {len(common['common_ground'])} areas")
# Output: "Common ground: 1 areas" (Fast response)

print(f"Conflicts: {len(common['conflicts'])} areas")
# Output: "Conflicts: 0 areas" (Non-negotiables don't conflict)

# Unique positions
unique = common["unique_positions"]
print(f"Analytical unique: {unique.get('analytical', [])}")
# Output: ["Natural language understanding", "Easy for users"]

print(f"Technical unique: {unique.get('technical', [])}")
# Output: ["No complex dependencies", "Easy to debug"]

# After discussion, track agreement
builder.track_agreement(
    teams_agreeing=["analytical", "technical"],
    agreed_point="Use weighted keyword matching with <10ms latency",
    rationale="Balances simplicity (technical need) with accuracy (analytical need)"
)

# Check consensus
score = builder.get_consensus_score()
print(f"Consensus: {score:.0%}")
# Output: "Consensus: 67%" (Moderate consensus achieved)

# Get alignment
alignment = builder.get_team_alignment()
print(f"Analytical alignment: {alignment['analytical']:.0%}")
print(f"Technical alignment: {alignment['technical']:.0%}")
```

---

## ğŸ“Š Real-World Example

From `CROSS_TEAM_COLLABORATION_MULTI_TURN.md`:

```python
builder = ConsensusBuilder(
    topic="Sprint 1 Implementation Details",
    teams=["analytical", "technical"]
)

# Analytical Team Position
builder.register_position(
    team="analytical",
    position="Prioritize user experience and accuracy",
    key_points=[
        "Natural language skills routing",
        "Confidence scorer (80% threshold)",
        "User-friendly error messages",
        "Target: 200ms latency"
    ],
    non_negotiables=["Accuracy > 80%"]
)

# Technical Team Position
builder.register_position(
    team="technical",
    position="Prioritize simplicity and performance",
    key_points=[
        "Simple keyword matching",
        "In-memory JSON storage",
        "Target: <10ms latency",
        "Zero external dependencies"
    ],
    non_negotiables=["Simple implementation"]
)

# Find common ground
common = builder.find_common_ground()

# Common: Both want fast response (though different targets)
print(f"Agreement areas: {common['agreement_areas']}")  # 1

# After multi-turn discussion
builder.track_agreement(
    ["analytical", "technical"],
    "Use simple keyword matching",
    "Technical challenge accepted by analytical team"
)

builder.track_agreement(
    ["analytical", "technical"],
    "Target <10ms latency",
    "Better than 200ms, both teams happy"
)

builder.track_agreement(
    ["analytical", "technical"],
    "Use JSON file with hot reload",
    "Simpler than PostgreSQL, maintains flexibility"
)

# Final consensus
score = builder.get_consensus_score()
print(f"Final consensus: {score:.0%}")  # 85% - High consensus!

# Team alignment
alignment = builder.get_team_alignment()
print(f"Analytical: {alignment['analytical']:.0%}")  # 100% (in all agreements)
print(f"Technical: {alignment['technical']:.0%}")   # 100% (in all agreements)
```

---

## ğŸ¯ Consensus Scoring

### Formula

```
consensus_score = (agreements + common_ground) / total_key_points
```

### Interpretation

| Score | Level | Meaning |
|-------|-------|---------|
| 0.0 - 0.3 | Low | Significant disagreement, more work needed |
| 0.3 - 0.5 | Moderate-Low | Some common ground, gaps remain |
| 0.5 - 0.7 | Moderate | Reasonable agreement, refinement needed |
| 0.7 - 0.9 | High | Strong consensus, minor details left |
| 0.9 - 1.0 | Very High | Near-complete agreement, ready to proceed |

---

## ğŸ” Common Ground Detection

### Similarity Algorithm

**Step 1:** Extract keywords from key points
```python
"Fast response" â†’ ["fast", "response"]
"Very fast" â†’ ["very", "fast"]
```

**Step 2:** Compare keyword overlap
```python
overlap = len(keywords1 & keywords2)
similarity = overlap / min(len(keywords1), len(keywords2))
```

**Step 3:** Threshold check
```python
if similarity > 0.5:  # >50% overlap
    considered_similar = True
```

### Conflict Detection

**Checks for:**
1. Negation patterns ("no X" vs "X")
2. Contradictory statements
3. Non-negotiable conflicts

---

## ğŸ¤ Compromise Generation

### Automatic Proposals

**For conflicts:**
- Identify middle ground
- Suggest optional features
- Recommend discussion

**For unique positions:**
- Mark as team-specific
- Suggest making optional
- Evaluate trade-offs

---

## ğŸ”„ Integration with Previous Components

### With MultiTurnConversation

```python
conv = MultiTurnConversation(topic="Implementation", teams=["analytical", "technical"])
builder = ConsensusBuilder(topic="Implementation", teams=["analytical", "technical"])

# Turn 1: Analytical proposes
conv.add_turn(1, "analytical", "Lucas", "Proposal A", "proposal")
builder.register_position("analytical", "Proposal A", ["Point 1", "Point 2"])

# Turn 2: Technical proposes
conv.add_turn(2, "technical", "Tomasz", "Proposal B", "proposal")
builder.register_position("technical", "Proposal B", ["Point 3", "Point 4"])

# Turn 3: Agreement
conv.add_turn(3, "analytical", "Sofia", "We agree on compromise", "agreement")
builder.track_agreement(["analytical", "technical"], "Compromise X", "Makes sense")

# Check consensus
score = builder.get_consensus_score()
print(f"Consensus after {len(conv.turns)} turns: {score:.0%}")
```

### With FeedbackLoopTracker

```python
feedback = FeedbackLoopTracker()
builder = ConsensusBuilder(topic="Storage Choice", teams=["analytical", "technical"])

# Positions
builder.register_position("analytical", "Use PostgreSQL", ["Persistent", "Reliable"])
builder.register_position("technical", "Use JSON", ["Simple", "Fast"])

# Challenge
loop_id = feedback.track_challenge(
    "Maria", "technical", "PostgreSQL proposal",
    "complexity", "PostgreSQL", "Too complex for static data"
)

# Response with agreement
feedback.track_response(loop_id, "Viktor", "accept", "Good point", "Use JSON")
builder.track_agreement(["analytical", "technical"], "Use JSON", "Simpler for static data")

# Both systems show collaboration success
assert feedback.get_improvement_metrics()["improvement_rate"] == 1.0
assert builder.get_consensus_score() > 0.5
```

---

## âœ… Testing

Tested scenarios:
- âœ… Position registration (with non-negotiables)
- âœ… Common ground detection
- âœ… Conflict detection
- âœ… Agreement tracking
- âœ… Disagreement tracking
- âœ… Consensus scoring
- âœ… Compromise proposals
- âœ… Team alignment
- âœ… Agreement breakdown
- âœ… Export functionality

---

## ğŸ“ Next Steps

**Step 5:** Implement CollaborationPatternRecognizer
- Pattern recognition
- Success indicator detection
- Best practices extraction
- Learning from history

---

**Implemented by:** Aleksander Nowak (Technical Team)  
**Reviewed by:** Helena Kowalczyk (Documentation)  
**Date:** November 4, 2025  
**Status:** âœ… Complete and tested
